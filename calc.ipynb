{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89ee7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39dee0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#webcam \n",
    "cap=cv2.VideoCapture(0)\n",
    "cap.set(3,1280) #width\n",
    "cap.set(4,720) #height\n",
    "detector=HandDetector(detectionCon=0.5,maxHands=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07949dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating button class\n",
    "class Button:\n",
    "    def __init__(self,pos,width,height,text):\n",
    "        self.pos=pos\n",
    "        self.width=width\n",
    "        self.height=height\n",
    "        self.text=text\n",
    "    \n",
    "    def draw(self,img):\n",
    "        cv2.rectangle(img, self.pos, (self.pos[0]+self.width,self.pos[1]+self.height), (225, 225, 225), cv2.FILLED) # Draw a rectangle around the image\n",
    "        cv2.rectangle(img, self.pos, (self.pos[0]+self.width,self.pos[1]+self.height), (50,50,50), 3) # Draw a rectangle around the image\n",
    "        cv2.putText(img,self.text,(self.pos[0]+40,self.pos[1]+60),cv2.FONT_HERSHEY_PLAIN,2,(255,0,0),2) \n",
    "    \n",
    "    def click(self,x,y):\n",
    "        if self.pos[0]<x<self.pos[0]+self.width and self.pos[1]<y<self.pos[1]+self.height:\n",
    "            cv2.rectangle(img, self.pos, (self.pos[0]+self.width,self.pos[1]+self.height), (255, 255, 255), cv2.FILLED) # Draw a rectangle around the image\n",
    "            cv2.rectangle(img, self.pos, (self.pos[0]+self.width,self.pos[1]+self.height), (50,50,50), 3) # Draw a rectangle around the image\n",
    "            cv2.putText(img,self.text,(self.pos[0]+30,self.pos[1]+70),cv2.FONT_HERSHEY_PLAIN,4,(0,0,0),4) \n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc8212b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a button\n",
    "button_list_values = [[\"7\",\"8\",\"9\",\"*\"],\n",
    "                      [\"4\",\"5\",\"6\",\"-\"],\n",
    "                      [\"1\",\"2\",\"3\",\"+\"],\n",
    "                      [\"0\",\"/\",\".\",\"=\"]]\n",
    "\n",
    "button_list = []\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        xpos = i*100 + 400\n",
    "        ypos = j*100 + 150\n",
    "        button_list.append(Button((xpos,ypos),100,100,button_list_values[j][i]))\n",
    "\n",
    "myEquation = \"10+5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b86950c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m img = cv2.flip(img, \u001b[32m1\u001b[39m) \u001b[38;5;66;03m# Flip the image horizontally\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#create hand detector object\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m hands,img= \u001b[43mdetector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfindHands\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mflipType\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#flipType=False to avoid flipping the image again \u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m#drew the button\u001b[39;00m\n\u001b[32m     10\u001b[39m cv2.rectangle(img, (\u001b[32m400\u001b[39m,\u001b[32m50\u001b[39m), (\u001b[32m400\u001b[39m+\u001b[32m400\u001b[39m,\u001b[32m50\u001b[39m+\u001b[32m100\u001b[39m), (\u001b[32m225\u001b[39m, \u001b[32m225\u001b[39m, \u001b[32m225\u001b[39m), cv2.FILLED)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sunny\\projects\\virtual_calculator\\.venv\\Lib\\site-packages\\cvzone\\HandTrackingModule.py:55\u001b[39m, in \u001b[36mHandDetector.findHands\u001b[39m\u001b[34m(self, img, draw, flipType)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[33;03mFinds hands in a BGR image.\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[33;03m:param img: Image to find the hands in.\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[33;03m:param draw: Flag to draw the output on the image.\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[33;03m:return: Image with or without drawings\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     54\u001b[39m imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28mself\u001b[39m.results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhands\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgRGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m allHands = []\n\u001b[32m     57\u001b[39m h, w, c = img.shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sunny\\projects\\virtual_calculator\\.venv\\Lib\\site-packages\\mediapipe\\python\\solutions\\hands.py:153\u001b[39m, in \u001b[36mHands.process\u001b[39m\u001b[34m(self, image)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np.ndarray) -> NamedTuple:\n\u001b[32m    133\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Processes an RGB image and returns the hand landmarks and handedness of each detected hand.\u001b[39;00m\n\u001b[32m    134\u001b[39m \n\u001b[32m    135\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    150\u001b[39m \u001b[33;03m         right hand) of the detected hand.\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimage\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sunny\\projects\\virtual_calculator\\.venv\\Lib\\site-packages\\mediapipe\\python\\solution_base.py:340\u001b[39m, in \u001b[36mSolutionBase.process\u001b[39m\u001b[34m(self, input_data)\u001b[39m\n\u001b[32m    334\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    335\u001b[39m     \u001b[38;5;28mself\u001b[39m._graph.add_packet_to_input_stream(\n\u001b[32m    336\u001b[39m         stream=stream_name,\n\u001b[32m    337\u001b[39m         packet=\u001b[38;5;28mself\u001b[39m._make_packet(input_stream_type,\n\u001b[32m    338\u001b[39m                                  data).at(\u001b[38;5;28mself\u001b[39m._simulated_timestamp))\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_graph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._output_stream_type_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#loop to capture video\n",
    "while True:\n",
    "    #get image from camera\n",
    "    success,img=cap.read()\n",
    "    img = cv2.flip(img, 1) # Flip the image horizontally\n",
    "    #create hand detector object\n",
    "    hands,img= detector.findHands(img,flipType=False) #flipType=False to avoid flipping the image again \n",
    "    \n",
    "    #drew the button\n",
    "    cv2.rectangle(img, (400,50), (400+400,50+100), (225, 225, 225), cv2.FILLED)\n",
    "    cv2.rectangle(img, (400,50), (400+400,50+100), (50,50,50), 3)\n",
    "    for button in button_list:\n",
    "        button.draw(img)\n",
    "    \n",
    "    #check if hands are detected\n",
    "    if hands:\n",
    "        lmList = hands[0][\"lmList\"] #get the landmark list of the first hand\n",
    "        length, _, img = detector.findDistance(lmList[4][:2], lmList[8][:2], img) #find the distance between the index finger and thumb \n",
    "        x,y = lmList[8][:2]\n",
    "        if length<50:\n",
    "            for button in button_list:\n",
    "                if button.click(x,y):\n",
    "                    \n",
    "    #output screen\n",
    "    cv2.putText(img,myEquation,(420,120),cv2.FONT_HERSHEY_PLAIN,2,(255,0,0),2) \n",
    "    \n",
    "    #display the image\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce64035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
